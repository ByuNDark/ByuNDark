{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db582fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1818f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data = pd.read_csv('m0728.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d12f2bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>가사</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8741</td>\n",
       "      <td>단 한번 단 한번밖에 못해도 그래도 널 사랑할 수 있을까 내 전불 다 걸고 내 앞에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8744</td>\n",
       "      <td>시간을 멈출수 있다면 온 힘을 다해 막을텐데 어쩌면 우리 오늘이 마지막인데 잠시후면...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8745</td>\n",
       "      <td>그리던 꿈처럼 내 맘속에 갑자기 찾아온 그대 멀리서 바라만 봤었던 하늘의 조각이었는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8747</td>\n",
       "      <td>보랏빛으로 물든 하늘 쓸쓸한 바람에 더욱 시려오는 밤 내 맘에 새겨진 익숙한 기억들...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8749</td>\n",
       "      <td>믿을수 있나요 나의 꿈 속에서 너는 마법에 빠진 공주란 걸 언제나 너를 향한 몸짓엔...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>14588</td>\n",
       "      <td>애써 나 웃어봐도 웃으려는게 더 슬퍼 보여 내 눈빛은 솔직해 안 슬프단 거짓말도 보...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5462</th>\n",
       "      <td>14589</td>\n",
       "      <td>자다 일어난 네 얼굴도 나에게는 보여도 좋아 술에 취해 털어 논 얘기들은 끝까지 꼭...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5463</th>\n",
       "      <td>14590</td>\n",
       "      <td>현아 날 버리지 말아요 현아 날 떠나지 말아요 현아 당신 떠나시면 이 슬픔 정말 어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>14591</td>\n",
       "      <td>그때는 믿지 않았지 웃어버렸지 사랑하면서도 헤어져야 한다는 말에 아직도 믿진 않지만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>14592</td>\n",
       "      <td>단 한번 단 한번밖에 못해도 그래도 널 사랑할 수 있을까 내 전불 다 걸고 내 앞에...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5466 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                                 가사\n",
       "0           8741  단 한번 단 한번밖에 못해도 그래도 널 사랑할 수 있을까 내 전불 다 걸고 내 앞에...\n",
       "1           8744  시간을 멈출수 있다면 온 힘을 다해 막을텐데 어쩌면 우리 오늘이 마지막인데 잠시후면...\n",
       "2           8745  그리던 꿈처럼 내 맘속에 갑자기 찾아온 그대 멀리서 바라만 봤었던 하늘의 조각이었는...\n",
       "3           8747  보랏빛으로 물든 하늘 쓸쓸한 바람에 더욱 시려오는 밤 내 맘에 새겨진 익숙한 기억들...\n",
       "4           8749  믿을수 있나요 나의 꿈 속에서 너는 마법에 빠진 공주란 걸 언제나 너를 향한 몸짓엔...\n",
       "...          ...                                                ...\n",
       "5461       14588  애써 나 웃어봐도 웃으려는게 더 슬퍼 보여 내 눈빛은 솔직해 안 슬프단 거짓말도 보...\n",
       "5462       14589  자다 일어난 네 얼굴도 나에게는 보여도 좋아 술에 취해 털어 논 얘기들은 끝까지 꼭...\n",
       "5463       14590  현아 날 버리지 말아요 현아 날 떠나지 말아요 현아 당신 떠나시면 이 슬픔 정말 어...\n",
       "5464       14591  그때는 믿지 않았지 웃어버렸지 사랑하면서도 헤어져야 한다는 말에 아직도 믿진 않지만...\n",
       "5465       14592  단 한번 단 한번밖에 못해도 그래도 널 사랑할 수 있을까 내 전불 다 걸고 내 앞에...\n",
       "\n",
       "[5466 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9da0aeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/d406q2cs0jx8y9m35w0pn47w0000gn/T/ipykernel_21529/1895184081.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  first_data['가사'] = first_data['가사'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\")\n",
      "/var/folders/c4/d406q2cs0jx8y9m35w0pn47w0000gn/T/ipykernel_21529/1895184081.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  first_data['가사'] = first_data['가사'].str.replace('^ +', \"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>가사</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8741</td>\n",
       "      <td>단 한번 단 한번밖에 못해도 그래도 널 사랑할 수 있을까 내 전불 다 걸고 내 앞에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8744</td>\n",
       "      <td>시간을 멈출수 있다면 온 힘을 다해 막을텐데 어쩌면 우리 오늘이 마지막인데 잠시후면...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8745</td>\n",
       "      <td>그리던 꿈처럼 내 맘속에 갑자기 찾아온 그대 멀리서 바라만 봤었던 하늘의 조각이었는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8747</td>\n",
       "      <td>보랏빛으로 물든 하늘 쓸쓸한 바람에 더욱 시려오는 밤 내 맘에 새겨진 익숙한 기억들...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8749</td>\n",
       "      <td>믿을수 있나요 나의 꿈 속에서 너는 마법에 빠진 공주란 걸 언제나 너를 향한 몸짓엔...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>14588</td>\n",
       "      <td>애써 나 웃어봐도 웃으려는게 더 슬퍼 보여 내 눈빛은 솔직해 안 슬프단 거짓말도 보...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5462</th>\n",
       "      <td>14589</td>\n",
       "      <td>자다 일어난 네 얼굴도 나에게는 보여도 좋아 술에 취해 털어 논 얘기들은 끝까지 꼭...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5463</th>\n",
       "      <td>14590</td>\n",
       "      <td>현아 날 버리지 말아요 현아 날 떠나지 말아요 현아 당신 떠나시면 이 슬픔 정말 어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>14591</td>\n",
       "      <td>그때는 믿지 않았지 웃어버렸지 사랑하면서도 헤어져야 한다는 말에 아직도 믿진 않지만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>14592</td>\n",
       "      <td>단 한번 단 한번밖에 못해도 그래도 널 사랑할 수 있을까 내 전불 다 걸고 내 앞에...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                                 가사\n",
       "0           8741  단 한번 단 한번밖에 못해도 그래도 널 사랑할 수 있을까 내 전불 다 걸고 내 앞에...\n",
       "1           8744  시간을 멈출수 있다면 온 힘을 다해 막을텐데 어쩌면 우리 오늘이 마지막인데 잠시후면...\n",
       "2           8745  그리던 꿈처럼 내 맘속에 갑자기 찾아온 그대 멀리서 바라만 봤었던 하늘의 조각이었는...\n",
       "3           8747  보랏빛으로 물든 하늘 쓸쓸한 바람에 더욱 시려오는 밤 내 맘에 새겨진 익숙한 기억들...\n",
       "4           8749  믿을수 있나요 나의 꿈 속에서 너는 마법에 빠진 공주란 걸 언제나 너를 향한 몸짓엔...\n",
       "...          ...                                                ...\n",
       "5461       14588  애써 나 웃어봐도 웃으려는게 더 슬퍼 보여 내 눈빛은 솔직해 안 슬프단 거짓말도 보...\n",
       "5462       14589  자다 일어난 네 얼굴도 나에게는 보여도 좋아 술에 취해 털어 논 얘기들은 끝까지 꼭...\n",
       "5463       14590  현아 날 버리지 말아요 현아 날 떠나지 말아요 현아 당신 떠나시면 이 슬픔 정말 어...\n",
       "5464       14591  그때는 믿지 않았지 웃어버렸지 사랑하면서도 헤어져야 한다는 말에 아직도 믿진 않지만...\n",
       "5465       14592  단 한번 단 한번밖에 못해도 그래도 널 사랑할 수 있을까 내 전불 다 걸고 내 앞에...\n",
       "\n",
       "[5370 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_data['가사'] = first_data['가사'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\")\n",
    "first_data['가사'] = first_data['가사'].str.replace('^ +', \"\")\n",
    "first_data['가사'].replace('', np.nan, inplace=True)\n",
    "first_data = first_data.dropna(how='any')\n",
    "second_data = first_data.drop_duplicates()\n",
    "second_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1fb63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code만 내가 직접 만든 것이다.\n",
    "second_data = second_data.sample(frac=1).reset_index(drop=True)\n",
    "Q = [];A = [];label = []\n",
    "for i in range(5370):\n",
    "    t = len(second_data['가사'][i]) // 12\n",
    "    Q.append(second_data['가사'][i][:t])\n",
    "    A.append(second_data['가사'][i][t:])\n",
    "    label.append(random.randint(0, 2))\n",
    "    \n",
    "Merge_Q = pd.Series(Q, name = 'Q')\n",
    "Merge_A = pd.Series(A, name = 'A')\n",
    "Merge_label = pd.Series(label, name = 'label')\n",
    "train_data = pd.concat([Merge_Q, Merge_A, Merge_label], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d75288cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>떠나 가 버린 그대 이젠 이해 할 수 있지만 아직도 내가 슬</td>\n",
       "      <td>픈건 잘해주지 못했던 미련이 남아 행복해 줘요 내가 당신을 아프게 했던 만큼 다시 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>첫눈에 반했단 걸 알아요 그대가 말한 사람 나죠 가슴이 뛰는 것도 들려요 그대 맘 ...</td>\n",
       "      <td>나도 그래요 애쓰면서 한 척 했죠   이리 와봐요 이제 내가 안아줄게요 그대보다...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>사실은 내가 못됐어 내가 정말 나쁜 놈이야 남자답지 못했어 나 이제와서 이러는 나야...</td>\n",
       "      <td>사랑한단 말 한마디 못했어 니 사랑을 이젠 알 것 같은데 내게 돌아오는 말 전부 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>조금 떨리지만 용기 낼게요 쉽진 않겠지만 꺼내 볼게요 내 맘속 깊은 곳에서 들려주</td>\n",
       "      <td>고 싶은 조금은 어색한 이야기  하얗게 번진 입김 사이로 작은 모습까지 선명하죠  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>얼어붙은 시선 메마른 입술 멈춰버린 이야기들 아무도 모</td>\n",
       "      <td>르는 저 깊은 곳에 사는 날 찾아        이 모든 아픔이 다 사라지기를    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>한 번 더 나를 믿어주겠니 지겹겠지만 이번만 세상 모두 욕한다 해도</td>\n",
       "      <td>너를 떠날 수는 없잖아 내가 많이 필요했던 그날인 걸 알아 그땐 어쩔 수가 없어 정...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>왜 내게 그런 말을 못하니 아직도 내가 타인처럼 느껴지니 헤어질 때면 작은</td>\n",
       "      <td>소리로 나에게 말하지 전화할게 예예예 그렇지만 한번이라도 전화로 내게 말을 한적 없...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>이해해 줘 괜찮다 해줘 수고했다 해줘 덕분이라 해줘 너 없</td>\n",
       "      <td>었음 어쩔뻔했냐고 네가 있어서 참 다행이라고 그리웠다 내게 말해줘 네가 없어서 참 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>다가가도 나 괜찮은 걸까 겁이나 멈춰서있어 정말 우린 만나야 했을까 대답을 할 수가...</td>\n",
       "      <td>파서 다시 사랑한다는 말을 할 수가 있을까 너를 버리고 버려도 결국 너로 채워져 아...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>부산에 가면 다시 너를 볼 수 있을</td>\n",
       "      <td>까 고운 머릿결을 흩날리며 나를 반겼던 그 부산역 앞은 참 많이도 변했구나 어디로 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5370 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Q  \\\n",
       "0                     떠나 가 버린 그대 이젠 이해 할 수 있지만 아직도 내가 슬   \n",
       "1     첫눈에 반했단 걸 알아요 그대가 말한 사람 나죠 가슴이 뛰는 것도 들려요 그대 맘 ...   \n",
       "2     사실은 내가 못됐어 내가 정말 나쁜 놈이야 남자답지 못했어 나 이제와서 이러는 나야...   \n",
       "3         조금 떨리지만 용기 낼게요 쉽진 않겠지만 꺼내 볼게요 내 맘속 깊은 곳에서 들려주   \n",
       "4                        얼어붙은 시선 메마른 입술 멈춰버린 이야기들 아무도 모   \n",
       "...                                                 ...   \n",
       "5365             한 번 더 나를 믿어주겠니 지겹겠지만 이번만 세상 모두 욕한다 해도    \n",
       "5366         왜 내게 그런 말을 못하니 아직도 내가 타인처럼 느껴지니 헤어질 때면 작은    \n",
       "5367                   이해해 줘 괜찮다 해줘 수고했다 해줘 덕분이라 해줘 너 없   \n",
       "5368  다가가도 나 괜찮은 걸까 겁이나 멈춰서있어 정말 우린 만나야 했을까 대답을 할 수가...   \n",
       "5369                                부산에 가면 다시 너를 볼 수 있을   \n",
       "\n",
       "                                                      A  label  \n",
       "0     픈건 잘해주지 못했던 미련이 남아 행복해 줘요 내가 당신을 아프게 했던 만큼 다시 ...      1  \n",
       "1       나도 그래요 애쓰면서 한 척 했죠   이리 와봐요 이제 내가 안아줄게요 그대보다...      2  \n",
       "2      사랑한단 말 한마디 못했어 니 사랑을 이젠 알 것 같은데 내게 돌아오는 말 전부 ...      2  \n",
       "3     고 싶은 조금은 어색한 이야기  하얗게 번진 입김 사이로 작은 모습까지 선명하죠  ...      0  \n",
       "4     르는 저 깊은 곳에 사는 날 찾아        이 모든 아픔이 다 사라지기를    ...      1  \n",
       "...                                                 ...    ...  \n",
       "5365  너를 떠날 수는 없잖아 내가 많이 필요했던 그날인 걸 알아 그땐 어쩔 수가 없어 정...      2  \n",
       "5366  소리로 나에게 말하지 전화할게 예예예 그렇지만 한번이라도 전화로 내게 말을 한적 없...      2  \n",
       "5367  었음 어쩔뻔했냐고 네가 있어서 참 다행이라고 그리웠다 내게 말해줘 네가 없어서 참 ...      0  \n",
       "5368  파서 다시 사랑한다는 말을 할 수가 있을까 너를 버리고 버려도 결국 너로 채워져 아...      0  \n",
       "5369  까 고운 머릿결을 흩날리며 나를 반겼던 그 부산역 앞은 참 많이도 변했구나 어디로 ...      2  \n",
       "\n",
       "[5370 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35ca6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "        # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        angle_rads = np.zeros(angle_rads.shape)\n",
    "        angle_rads[:, 0::2] = sines\n",
    "        angle_rads[:, 1::2] = cosines\n",
    "        pos_encoding = tf.constant(angle_rads)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13bb42f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b00a2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티 헤드 어텐션\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        # d_model을 num_heads로 나눈 값.\n",
    "        # 논문 기준 : 64\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # WO에 해당하는 밀집층 정의\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "        # q : (batch_size, query의 문장 길이, d_model)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 2. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 4. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 5. WO에 해당하는 밀집층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d6242b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 마스크\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, key의 문장 길이)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ded9156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 레이어\n",
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': padding_mask # 패딩 마스크 사용\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb881753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 인코더는 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d1a4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "619189fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 레이어\n",
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "            'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "        })\n",
    "\n",
    "    # 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "            'mask': padding_mask # 패딩 마스크\n",
    "        })\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbdfaaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "    # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 디코더를 num_layers개 쌓기\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "224a5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머\n",
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더의 패딩 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 디코더의 패딩 마스크(두번째 서브층)\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "        d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 다음 단어 예측을 위한 출력층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c91bd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_transformer = transformer(\n",
    "#     vocab_size = 9000,\n",
    "#     num_layers = 4,\n",
    "#     dff = 512,\n",
    "#     d_model = 128,\n",
    "#     num_heads = 4,\n",
    "#     dropout = 0.3,\n",
    "#     name=\"small_transformer\")\n",
    "\n",
    "# tf.keras.utils.plot_model(\n",
    "#     small_transformer, to_file='small_transformer.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "640eb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차 함수\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc9343b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e868d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "281cd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7246128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서브워드텍스트인코더를 사용하여 질문과 답변을 모두 포함한 단어 집합(Vocabulary) 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c205935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 80으로 정의\n",
    "MAX_LENGTH = 80\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        tokenized_inputs.append(sentence1)\n",
    "        tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "279a25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "547dd432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
    "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0dc7ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8119, 256)\n",
      "(1, 8119, 256)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyper-parameters\n",
    "NUM_LAYERS = 2\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eee3f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 80\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5519cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/84 [==============================] - 65s 750ms/step - loss: 8.9008 - accuracy: 0.0075\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 65s 774ms/step - loss: 8.5737 - accuracy: 0.0190\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 64s 760ms/step - loss: 8.1296 - accuracy: 0.0191\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 63s 756ms/step - loss: 7.8059 - accuracy: 0.0273\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 64s 762ms/step - loss: 7.6948 - accuracy: 0.0311\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 64s 762ms/step - loss: 7.6235 - accuracy: 0.0359\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 66s 782ms/step - loss: 7.4800 - accuracy: 0.0498\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 64s 760ms/step - loss: 7.2346 - accuracy: 0.0627\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 64s 760ms/step - loss: 6.9307 - accuracy: 0.0757\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 64s 762ms/step - loss: 6.6541 - accuracy: 0.0893\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 6.4072 - accuracy: 0.1015\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 65s 771ms/step - loss: 6.1857 - accuracy: 0.1125\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 66s 784ms/step - loss: 5.9828 - accuracy: 0.1234\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 66s 779ms/step - loss: 5.7928 - accuracy: 0.1339\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 63s 752ms/step - loss: 5.6056 - accuracy: 0.1455\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 64s 763ms/step - loss: 5.4266 - accuracy: 0.1570\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 64s 764ms/step - loss: 5.2497 - accuracy: 0.1684\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 66s 782ms/step - loss: 5.0727 - accuracy: 0.1809\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 64s 760ms/step - loss: 4.8972 - accuracy: 0.1938\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 63s 748ms/step - loss: 4.7188 - accuracy: 0.2084\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 63s 753ms/step - loss: 4.5389 - accuracy: 0.2240\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 65s 771ms/step - loss: 4.3558 - accuracy: 0.2414\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 64s 763ms/step - loss: 4.1704 - accuracy: 0.2604\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 64s 768ms/step - loss: 3.9847 - accuracy: 0.2808\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 63s 749ms/step - loss: 3.7972 - accuracy: 0.3027\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 63s 748ms/step - loss: 3.6082 - accuracy: 0.3255\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 62s 735ms/step - loss: 3.4198 - accuracy: 0.3504\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 63s 745ms/step - loss: 3.2349 - accuracy: 0.3752\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 62s 740ms/step - loss: 3.0437 - accuracy: 0.4006\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 63s 756ms/step - loss: 2.8637 - accuracy: 0.4277\n",
      "CPU times: user 2h 59min 18s, sys: 15min 20s, total: 3h 14min 39s\n",
      "Wall time: 31min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1319a29a0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "EPOCHS = 30\n",
    "\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7504bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "        # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "633ab01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # 단어와 구두점 사이에 공백 추가.\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4103fcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 눈을 깜빡한 사이\n",
      "Output: 아 하얀 눈이 내려와 그리워 그리워 그리워 그리워 그리워 그리워 그리워 그리워 그리워 그리워 질때 때로는 애에 젖곤 해 아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 님아 야\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"눈을 깜빡한 사이\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08cf0e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 시간을 다시 되돌리고 싶\n",
      "Output: 읰눈이 날아와요 길을 걷죠 오   그대는 꽃피죠 오듯 한 송이 꽃이 되어 나를 꼭 잡고 걸어가요 나는 꽃으로 나를 데려가 줘요 나는 꽃피운 세상속에서 꿈을 꾸어요 나는 꿈을 꾸어\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"시간을 다시 되돌리고 싶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c38bc141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 계단에 벌레가 있는데 나는 그것을 처음 발견한\n",
      "Output: 눈을 감고 너를 위한 거야 너를 위해 쓰고 걷던 거리를 걷고 싶어져 너와 걷던 많은 기억들이 날 너와 걷던 거리를 혼자 걷고 싶어져 너와 걷던 거리를 혼자 걷고 있어 너와 걷고 있어 너와 걷고 있어 너와 걷고 있어 너와 걷던 너와 눈을 감으면 너와 눈을 감으면 너와 눈을 감으면 너와 걷던 너와 눈을 감으면 너와 걷고 너와 걷고 너와 걷던 거리를 혼자 걷고 있어 너와 걷던 너와 함께 걷던 너와 함께 걷던 그 길을 혼자 걷고 있어 그날\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"계단에 벌레가 있는데 나는 그것을 처음 발견한\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b682bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 친구들은 저만치 가네 만남을 앞에 두고서\n",
      "Output: 칔도 못하고 눈물만 흘리면 난 아무것도 못하고 잠도 못 이루면 안돼요 눈을 감아도 눈을 감아도 눈을 감아도 눈을 감아도 눈을 감아도 자꾸만 내 맘을 적셔요 눈을 감고 바람이 불며 우는 내 맘에 눈물이 난다 그대 이름과 그대의 이름조차 못하고 멀리서 이렇게 멀리서 이렇게 멀리서 이렇게 멀리서 바라볼 때 그대 이름조차 못하고 눈을 감아도 자꾸만 생각나 그대 이름조차 이렇게 그리운 이름조차 없는 그대를 찾죠 그대를\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"친구들은 저만치 가네 만남을 앞에 두고서\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
