{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01154c3f",
   "metadata": {},
   "source": [
    "# 딥러닝 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0a198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AllinOne():\n",
    "    print('임포팅...')\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import datasets, preprocessing, model_selection\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import datasets, utils\n",
    "    from tensorflow.keras import models, layers, activations, initializers, losses, optimizers, metrics\n",
    "    import os\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    print('임포팅 complete')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('data...')\n",
    "    test = pd.read_csv('./FIFA_test.csv')\n",
    "    train = pd.read_csv('./FIFA_train.csv')\n",
    "    submission = pd.read_csv('./submission.csv')\n",
    "    print('data complete')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('OHE...')\n",
    "    train_OHE = pd.get_dummies(train, columns=[\"continent\", \"position\", \"prefer_foot\"])\n",
    "    print('OHE complete(use train_OHE)')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('feature와 target 나누기')\n",
    "    x_data = train_OHE.drop(columns=[\"id\", \"name\", \"value\", \"contract_until\"])\n",
    "    y_data = train_OHE.value\n",
    "    train_data, test_data, train_label, test_label = model_selection.train_test_split(x_data, y_data,test_size=0.3,random_state=0)\n",
    "    print('트테트테의 결과')\n",
    "    print(train_data.shape)\n",
    "    print(test_data.shape)\n",
    "    print(train_label.shape)\n",
    "    print(test_label.shape)\n",
    "    sc = preprocessing.StandardScaler()\n",
    "    sc.fit(train_data)\n",
    "    train_data = sc.transform(train_data)\n",
    "    test_data = sc.transform(test_data)\n",
    "    print('standardscaler의 결과')\n",
    "    print(x_data.shape)\n",
    "    print(y_data.shape)\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('layer 나누기')\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(input_dim=16, units=8, activation=None, kernel_initializer=initializers.he_uniform()))\n",
    "    model.add(layers.Activation('elu'))\n",
    "\n",
    "    model.add(layers.Dense(units=8, activation=None, kernel_initializer=initializers.he_uniform()))\n",
    "    model.add(layers.Activation('elu'))\n",
    "\n",
    "    model.add(layers.Dense(units=8, activation=None, kernel_initializer=initializers.he_uniform()))\n",
    "    model.add(layers.Activation('elu'))\n",
    "    model.add(layers.Dropout(rate=0.4))\n",
    "\n",
    "    model.add(layers.Dense(units=1, activation=None))\n",
    "    print('layer 과정 완료')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('아담')\n",
    "    model.compile(optimizer=optimizers.Adam(),\n",
    "              loss=losses.mean_squared_error,\n",
    "              metrics=[metrics.mean_squared_error])\n",
    "    print('아담 완료')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    print('history에서 epoch 돌리기')\n",
    "    history = model.fit(train_data, train_label, batch_size=25, epochs=500, validation_split=0.3, verbose=0)\n",
    "    print('history에서 epoch 완료')\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    result = model.evaluate(test_data, test_label)\n",
    "    print('loss (mean_squared_error) :', np.sqrt(result[0]))\n",
    "    print('---------------------------------------------------------------------------------------------------')\n",
    "    loss = history.history['mean_squared_error']\n",
    "    val_loss = history.history['val_mean_squared_error']\n",
    "\n",
    "    x_len = np.arange(len(loss))\n",
    "\n",
    "    plt.plot(x_len, loss, marker='.', c='blue', label=\"Train-set loss.\")\n",
    "    plt.plot(x_len, val_loss, marker='.', c='red', label=\"Validation-set loss.\")\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Loss(MSE)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f416c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임포팅...\n",
      "임포팅 complete\n",
      "---------------------------------------------------------------------------------------------------\n",
      "data...\n",
      "data complete\n",
      "---------------------------------------------------------------------------------------------------\n",
      "OHE...\n",
      "OHE complete(use train_OHE)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "feature와 target 나누기\n",
      "트테트테의 결과\n",
      "(6252, 16)\n",
      "(2680, 16)\n",
      "(6252,)\n",
      "(2680,)\n",
      "standardscaler의 결과\n",
      "(8932, 16)\n",
      "(8932,)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "layer 나누기\n",
      "layer 과정 완료\n",
      "---------------------------------------------------------------------------------------------------\n",
      "아담\n",
      "아담 완료\n",
      "---------------------------------------------------------------------------------------------------\n",
      "history에서 epoch 돌리기\n",
      "history에서 epoch 완료\n",
      "---------------------------------------------------------------------------------------------------\n",
      "84/84 [==============================] - 0s 270us/step - loss: 5960542191616.0000 - mean_squared_error: 5960542191616.0000\n",
      "loss (mean_squared_error) : 2441422.1657910785\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "AllinOne()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad0abf5",
   "metadata": {},
   "source": [
    "# 딥러닝 + html 연동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531bf26b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임포팅...\n",
      "임포팅 complete\n",
      "---------------------------------------------------------------------------------------------------\n",
      "data...\n",
      "data complete\n",
      "---------------------------------------------------------------------------------------------------\n",
      "OHE...\n",
      "OHE complete(use train_OHE)\n",
      "---------------------------------------------------------------------------------------------------\n",
      "feature와 target 나누기\n",
      "---------------------------------------------------------------------------------------------------\n",
      "model 만들기\n",
      "완료\n",
      "---------------------------------------------------------------------------------------------------\n",
      "callback\n",
      "callback 완료\n",
      "---------------------------------------------------------------------------------------------------\n",
      "model epoch 돌리기\n",
      "Epoch 1/100\n",
      "224/358 [=================>............] - ETA: 0s - loss: -267006181376.0000 - accuracy: 0.0000e+00\n",
      "Epoch 1: loss improved from inf to -1434673872896.00000, saving model to Models/001--1434673872896.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 536us/step - loss: -1434673872896.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "296/358 [=======================>......] - ETA: 0s - loss: -20456065204224.0000 - accuracy: 0.0000e+00\n",
      "Epoch 2: loss improved from -1434673872896.00000 to -24601583157248.00000, saving model to Models/002--24601583157248.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 362us/step - loss: -24601583157248.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "302/358 [========================>.....] - ETA: 0s - loss: -98556480323584.0000 - accuracy: 0.0000e+00\n",
      "Epoch 3: loss improved from -24601583157248.00000 to -106811810119680.00000, saving model to Models/003--106811810119680.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 355us/step - loss: -106811810119680.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "278/358 [======================>.......] - ETA: 0s - loss: -249118421155840.0000 - accuracy: 0.0000e+00\n",
      "Epoch 4: loss improved from -106811810119680.00000 to -275249874599936.00000, saving model to Models/004--275249874599936.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 380us/step - loss: -275249874599936.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "293/358 [=======================>......] - ETA: 0s - loss: -527284746321920.0000 - accuracy: 0.0000e+00\n",
      "Epoch 5: loss improved from -275249874599936.00000 to -553667488907264.00000, saving model to Models/005--553667488907264.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 363us/step - loss: -553667488907264.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "298/358 [=======================>......] - ETA: 0s - loss: -907178093314048.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6: loss improved from -553667488907264.00000 to -959213836697600.00000, saving model to Models/006--959213836697600.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 357us/step - loss: -959213836697600.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "293/358 [=======================>......] - ETA: 0s - loss: -1468390799572992.0000 - accuracy: 0.0000e+00\n",
      "Epoch 7: loss improved from -959213836697600.00000 to -1499349326495744.00000, saving model to Models/007--1499349326495744.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 363us/step - loss: -1499349326495744.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "295/358 [=======================>......] - ETA: 0s - loss: -2085785369051136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8: loss improved from -1499349326495744.00000 to -2173193053798400.00000, saving model to Models/008--2173193053798400.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 360us/step - loss: -2173193053798400.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "298/358 [=======================>......] - ETA: 0s - loss: -2969306581172224.0000 - accuracy: 0.0000e+00\n",
      "Epoch 9: loss improved from -2173193053798400.00000 to -2990992407920640.00000, saving model to Models/009--2990992407920640.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 358us/step - loss: -2990992407920640.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "295/358 [=======================>......] - ETA: 0s - loss: -3804504847810560.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10: loss improved from -2990992407920640.00000 to -3963819143462912.00000, saving model to Models/010--3963819143462912.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 364us/step - loss: -3963819143462912.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "293/358 [=======================>......] - ETA: 0s - loss: -5030483666665472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11: loss improved from -3963819143462912.00000 to -5090325982871552.00000, saving model to Models/011--5090325982871552.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 365us/step - loss: -5090325982871552.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "298/358 [=======================>......] - ETA: 0s - loss: -6290479968681984.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12: loss improved from -5090325982871552.00000 to -6382217785769984.00000, saving model to Models/012--6382217785769984.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 357us/step - loss: -6382217785769984.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "298/358 [=======================>......] - ETA: 0s - loss: -7666024312733696.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13: loss improved from -6382217785769984.00000 to -7844462487142400.00000, saving model to Models/013--7844462487142400.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 359us/step - loss: -7844462487142400.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "295/358 [=======================>......] - ETA: 0s - loss: -9362270643552256.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14: loss improved from -7844462487142400.00000 to -9483389795041280.00000, saving model to Models/014--9483389795041280.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 361us/step - loss: -9483389795041280.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "294/358 [=======================>......] - ETA: 0s - loss: -10999595928649728.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15: loss improved from -9483389795041280.00000 to -11296676669030400.00000, saving model to Models/015--11296676669030400.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 362us/step - loss: -11296676669030400.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "300/358 [========================>.....] - ETA: 0s - loss: -13060768987611136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16: loss improved from -11296676669030400.00000 to -13294523656437760.00000, saving model to Models/016--13294523656437760.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 360us/step - loss: -13294523656437760.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "291/358 [=======================>......] - ETA: 0s - loss: -15342507944574976.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17: loss improved from -13294523656437760.00000 to -15483129468813312.00000, saving model to Models/017--15483129468813312.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 367us/step - loss: -15483129468813312.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "297/358 [=======================>......] - ETA: 0s - loss: -17615548519022592.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18: loss improved from -15483129468813312.00000 to -17874466327494656.00000, saving model to Models/018--17874466327494656.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 361us/step - loss: -17874466327494656.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "299/358 [========================>.....] - ETA: 0s - loss: -20133185333493760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19: loss improved from -17874466327494656.00000 to -20472225756872704.00000, saving model to Models/019--20472225756872704.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 359us/step - loss: -20472225756872704.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "301/358 [========================>.....] - ETA: 0s - loss: -22693804033179648.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20: loss improved from -20472225756872704.00000 to -23277279635308544.00000, saving model to Models/020--23277279635308544.0000-0.0000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s 354us/step - loss: -23277279635308544.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -26251963247099904.0000 - accuracy: 0.0000e+00\n",
      "Epoch 21: loss improved from -23277279635308544.00000 to -26302667483512832.00000, saving model to Models/021--26302667483512832.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -26302667483512832.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -29597869472219136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 22: loss improved from -26302667483512832.00000 to -29546016332054528.00000, saving model to Models/022--29546016332054528.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -29546016332054528.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -32278216827731968.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23: loss improved from -29546016332054528.00000 to -33027826059837440.00000, saving model to Models/023--33027826059837440.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -33027826059837440.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -36543084992921600.0000 - accuracy: 0.0000e+00\n",
      "Epoch 24: loss improved from -33027826059837440.00000 to -36724062029873152.00000, saving model to Models/024--36724062029873152.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -36724062029873152.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -39572681909075968.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25: loss improved from -36724062029873152.00000 to -40676041827549184.00000, saving model to Models/025--40676041827549184.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -40676041827549184.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -44701341011935232.0000 - accuracy: 0.0000e+00\n",
      "Epoch 26: loss improved from -40676041827549184.00000 to -44885801267363840.00000, saving model to Models/026--44885801267363840.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -44885801267363840.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "306/358 [========================>.....] - ETA: 0s - loss: -49695460264247296.0000 - accuracy: 0.0000e+00\n",
      "Epoch 27: loss improved from -44885801267363840.00000 to -49321261238583296.00000, saving model to Models/027--49321261238583296.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -49321261238583296.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -53713019917565952.0000 - accuracy: 0.0000e+00\n",
      "Epoch 28: loss improved from -49321261238583296.00000 to -54030761598124032.00000, saving model to Models/028--54030761598124032.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -54030761598124032.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -58304297007316992.0000 - accuracy: 0.0000e+00\n",
      "Epoch 29: loss improved from -54030761598124032.00000 to -58997990060195840.00000, saving model to Models/029--58997990060195840.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -58997990060195840.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -64003589760090112.0000 - accuracy: 0.0000e+00\n",
      "Epoch 30: loss improved from -58997990060195840.00000 to -64226172145238016.00000, saving model to Models/030--64226172145238016.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -64226172145238016.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "302/358 [========================>.....] - ETA: 0s - loss: -68305970169643008.0000 - accuracy: 0.0000e+00\n",
      "Epoch 31: loss improved from -64226172145238016.00000 to -69733488449814528.00000, saving model to Models/031--69733488449814528.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -69733488449814528.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -74612214815784960.0000 - accuracy: 0.0000e+00\n",
      "Epoch 32: loss improved from -69733488449814528.00000 to -75548698074939392.00000, saving model to Models/032--75548698074939392.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -75548698074939392.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -81469731399270400.0000 - accuracy: 0.0000e+00\n",
      "Epoch 33: loss improved from -75548698074939392.00000 to -81624204193038336.00000, saving model to Models/033--81624204193038336.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -81624204193038336.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -85115059121946624.0000 - accuracy: 0.0000e+00\n",
      "Epoch 34: loss improved from -81624204193038336.00000 to -87979115113611264.00000, saving model to Models/034--87979115113611264.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 401us/step - loss: -87979115113611264.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -94020828429025280.0000 - accuracy: 0.0000e+00\n",
      "Epoch 35: loss improved from -87979115113611264.00000 to -94637456883712000.00000, saving model to Models/035--94637456883712000.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -94637456883712000.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -101480748535513088.0000 - accuracy: 0.0000e+00\n",
      "Epoch 36: loss improved from -94637456883712000.00000 to -101603764988805120.00000, saving model to Models/036--101603764988805120.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -101603764988805120.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -109314339386687488.0000 - accuracy: 0.0000e+00\n",
      "Epoch 37: loss improved from -101603764988805120.00000 to -108917742106574848.00000, saving model to Models/037--108917742106574848.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -108917742106574848.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -114978868674166784.0000 - accuracy: 0.0000e+00\n",
      "Epoch 38: loss improved from -108917742106574848.00000 to -116578451934150656.00000, saving model to Models/038--116578451934150656.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -116578451934150656.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -124786555343601664.0000 - accuracy: 0.0000e+00\n",
      "Epoch 39: loss improved from -116578451934150656.00000 to -124514211467362304.00000, saving model to Models/039--124514211467362304.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -124514211467362304.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "302/358 [========================>.....] - ETA: 0s - loss: -132737089564311552.0000 - accuracy: 0.0000e+00\n",
      "Epoch 40: loss improved from -124514211467362304.00000 to -132759681092288512.00000, saving model to Models/040--132759681092288512.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -132759681092288512.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -141548721778196480.0000 - accuracy: 0.0000e+00\n",
      "Epoch 41: loss improved from -132759681092288512.00000 to -141344023636869120.00000, saving model to Models/041--141344023636869120.0000-0.0000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s 351us/step - loss: -141344023636869120.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -148530122398367744.0000 - accuracy: 0.0000e+00\n",
      "Epoch 42: loss improved from -141344023636869120.00000 to -150303926711746560.00000, saving model to Models/042--150303926711746560.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 351us/step - loss: -150303926711746560.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -159187293469409280.0000 - accuracy: 0.0000e+00\n",
      "Epoch 43: loss improved from -150303926711746560.00000 to -159578771148505088.00000, saving model to Models/043--159578771148505088.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -159578771148505088.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "307/358 [========================>.....] - ETA: 0s - loss: -168314253592231936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 44: loss improved from -159578771148505088.00000 to -169204239535439872.00000, saving model to Models/044--169204239535439872.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 347us/step - loss: -169204239535439872.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 45/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -180011614202757120.0000 - accuracy: 0.0000e+00\n",
      "Epoch 45: loss improved from -169204239535439872.00000 to -179183888105472000.00000, saving model to Models/045--179183888105472000.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -179183888105472000.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 46/100\n",
      "306/358 [========================>.....] - ETA: 0s - loss: -191731961478250496.0000 - accuracy: 0.0000e+00\n",
      "Epoch 46: loss improved from -179183888105472000.00000 to -189516325289197568.00000, saving model to Models/046--189516325289197568.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -189516325289197568.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 47/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -200543000986648576.0000 - accuracy: 0.0000e+00\n",
      "Epoch 47: loss improved from -189516325289197568.00000 to -200180694725427200.00000, saving model to Models/047--200180694725427200.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 351us/step - loss: -200180694725427200.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 48/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -211910439389364224.0000 - accuracy: 0.0000e+00\n",
      "Epoch 48: loss improved from -200180694725427200.00000 to -211312150445031424.00000, saving model to Models/048--211312150445031424.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -211312150445031424.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 49/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -222228273684283392.0000 - accuracy: 0.0000e+00\n",
      "Epoch 49: loss improved from -211312150445031424.00000 to -222816409325928448.00000, saving model to Models/049--222816409325928448.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 361us/step - loss: -222816409325928448.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 50/100\n",
      "302/358 [========================>.....] - ETA: 0s - loss: -234157906126176256.0000 - accuracy: 0.0000e+00\n",
      "Epoch 50: loss improved from -222816409325928448.00000 to -234758376913895424.00000, saving model to Models/050--234758376913895424.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -234758376913895424.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 51/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -243622794275848192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 51: loss improved from -234758376913895424.00000 to -247056191132270592.00000, saving model to Models/051--247056191132270592.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -247056191132270592.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 52/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -257336075096162304.0000 - accuracy: 0.0000e+00\n",
      "Epoch 52: loss improved from -247056191132270592.00000 to -259779533530464256.00000, saving model to Models/052--259779533530464256.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -259779533530464256.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 53/100\n",
      "298/358 [=======================>......] - ETA: 0s - loss: -268923725062078464.0000 - accuracy: 0.0000e+00\n",
      "Epoch 53: loss improved from -259779533530464256.00000 to -272896861868654592.00000, saving model to Models/053--272896861868654592.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 358us/step - loss: -272896861868654592.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 54/100\n",
      "302/358 [========================>.....] - ETA: 0s - loss: -287101779005407232.0000 - accuracy: 0.0000e+00\n",
      "Epoch 54: loss improved from -272896861868654592.00000 to -286412161876492288.00000, saving model to Models/054--286412161876492288.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -286412161876492288.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 55/100\n",
      "302/358 [========================>.....] - ETA: 0s - loss: -301641669231509504.0000 - accuracy: 0.0000e+00\n",
      "Epoch 55: loss improved from -286412161876492288.00000 to -300281916945334272.00000, saving model to Models/055--300281916945334272.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -300281916945334272.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 56/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -316374403489202176.0000 - accuracy: 0.0000e+00\n",
      "Epoch 56: loss improved from -300281916945334272.00000 to -314670194825887744.00000, saving model to Models/056--314670194825887744.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -314670194825887744.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 57/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -331773201275158528.0000 - accuracy: 0.0000e+00\n",
      "Epoch 57: loss improved from -314670194825887744.00000 to -329469655695491072.00000, saving model to Models/057--329469655695491072.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -329469655695491072.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 58/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -346978210136719360.0000 - accuracy: 0.0000e+00\n",
      "Epoch 58: loss improved from -329469655695491072.00000 to -344673084009086976.00000, saving model to Models/058--344673084009086976.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -344673084009086976.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 59/100\n",
      "302/358 [========================>.....] - ETA: 0s - loss: -364051426692825088.0000 - accuracy: 0.0000e+00\n",
      "Epoch 59: loss improved from -344673084009086976.00000 to -360360469237596160.00000, saving model to Models/059--360360469237596160.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -360360469237596160.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 60/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -374294167779540992.0000 - accuracy: 0.0000e+00\n",
      "Epoch 60: loss improved from -360360469237596160.00000 to -376572905628106752.00000, saving model to Models/060--376572905628106752.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -376572905628106752.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 61/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -386878696834727936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 61: loss improved from -376572905628106752.00000 to -393256276592689152.00000, saving model to Models/061--393256276592689152.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 351us/step - loss: -393256276592689152.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 62/100\n",
      "301/358 [========================>.....] - ETA: 0s - loss: -408488910683897856.0000 - accuracy: 0.0000e+00\n",
      "Epoch 62: loss improved from -393256276592689152.00000 to -410343924238909440.00000, saving model to Models/062--410343924238909440.0000-0.0000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s 353us/step - loss: -410343924238909440.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 63/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -421513656707055616.0000 - accuracy: 0.0000e+00\n",
      "Epoch 63: loss improved from -410343924238909440.00000 to -427942638633615360.00000, saving model to Models/063--427942638633615360.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -427942638633615360.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 64/100\n",
      "306/358 [========================>.....] - ETA: 0s - loss: -445041521914281984.0000 - accuracy: 0.0000e+00\n",
      "Epoch 64: loss improved from -427942638633615360.00000 to -445950577512284160.00000, saving model to Models/064--445950577512284160.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -445950577512284160.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 65/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -463529054021091328.0000 - accuracy: 0.0000e+00\n",
      "Epoch 65: loss improved from -445950577512284160.00000 to -464461646039875584.00000, saving model to Models/065--464461646039875584.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -464461646039875584.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 66/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -487187417514639360.0000 - accuracy: 0.0000e+00\n",
      "Epoch 66: loss improved from -464461646039875584.00000 to -483462375198949376.00000, saving model to Models/066--483462375198949376.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -483462375198949376.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 67/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -498805991245086720.0000 - accuracy: 0.0000e+00\n",
      "Epoch 67: loss improved from -483462375198949376.00000 to -502928266496049152.00000, saving model to Models/067--502928266496049152.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -502928266496049152.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 68/100\n",
      "306/358 [========================>.....] - ETA: 0s - loss: -522403709800415232.0000 - accuracy: 0.0000e+00\n",
      "Epoch 68: loss improved from -502928266496049152.00000 to -522921751575789568.00000, saving model to Models/068--522921751575789568.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -522921751575789568.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 69/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -542589059659202560.0000 - accuracy: 0.0000e+00\n",
      "Epoch 69: loss improved from -522921751575789568.00000 to -543414483654017024.00000, saving model to Models/069--543414483654017024.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -543414483654017024.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 70/100\n",
      "301/358 [========================>.....] - ETA: 0s - loss: -570439586111553536.0000 - accuracy: 0.0000e+00\n",
      "Epoch 70: loss improved from -543414483654017024.00000 to -564423058484363264.00000, saving model to Models/070--564423058484363264.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 356us/step - loss: -564423058484363264.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 71/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -598818221742620672.0000 - accuracy: 0.0000e+00\n",
      "Epoch 71: loss improved from -564423058484363264.00000 to -585826667226726400.00000, saving model to Models/071--585826667226726400.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -585826667226726400.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 72/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -603713522387386368.0000 - accuracy: 0.0000e+00\n",
      "Epoch 72: loss improved from -585826667226726400.00000 to -607827138984280064.00000, saving model to Models/072--607827138984280064.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -607827138984280064.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 73/100\n",
      "300/358 [========================>.....] - ETA: 0s - loss: -622648487007223808.0000 - accuracy: 0.0000e+00\n",
      "Epoch 73: loss improved from -607827138984280064.00000 to -630370288449617920.00000, saving model to Models/073--630370288449617920.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 354us/step - loss: -630370288449617920.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 74/100\n",
      "301/358 [========================>.....] - ETA: 0s - loss: -656478673087496192.0000 - accuracy: 0.0000e+00\n",
      "Epoch 74: loss improved from -630370288449617920.00000 to -653553834718658560.00000, saving model to Models/074--653553834718658560.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -653553834718658560.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 75/100\n",
      "301/358 [========================>.....] - ETA: 0s - loss: -684995125629157376.0000 - accuracy: 0.0000e+00\n",
      "Epoch 75: loss improved from -653553834718658560.00000 to -677086750807425024.00000, saving model to Models/075--677086750807425024.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -677086750807425024.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 76/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -689859846106775552.0000 - accuracy: 0.0000e+00\n",
      "Epoch 76: loss improved from -677086750807425024.00000 to -701227353228967936.00000, saving model to Models/076--701227353228967936.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -701227353228967936.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 77/100\n",
      "301/358 [========================>.....] - ETA: 0s - loss: -725192995862740992.0000 - accuracy: 0.0000e+00\n",
      "Epoch 77: loss improved from -701227353228967936.00000 to -725849404304523264.00000, saving model to Models/077--725849404304523264.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 354us/step - loss: -725849404304523264.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 78/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -760767694579433472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 78: loss improved from -725849404304523264.00000 to -750935311848046592.00000, saving model to Models/078--750935311848046592.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 351us/step - loss: -750935311848046592.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 79/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -775100790720167936.0000 - accuracy: 0.0000e+00\n",
      "Epoch 79: loss improved from -750935311848046592.00000 to -776639419804286976.00000, saving model to Models/079--776639419804286976.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 348us/step - loss: -776639419804286976.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 80/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -797444103947157504.0000 - accuracy: 0.0000e+00\n",
      "Epoch 80: loss improved from -776639419804286976.00000 to -802953550555512832.00000, saving model to Models/080--802953550555512832.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 351us/step - loss: -802953550555512832.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 81/100\n",
      "297/358 [=======================>......] - ETA: 0s - loss: -827826359001677824.0000 - accuracy: 0.0000e+00\n",
      "Epoch 81: loss improved from -802953550555512832.00000 to -829848292165681152.00000, saving model to Models/081--829848292165681152.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 358us/step - loss: -829848292165681152.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 82/100\n",
      "301/358 [========================>.....] - ETA: 0s - loss: -849284840246214656.0000 - accuracy: 0.0000e+00\n",
      "Epoch 82: loss improved from -829848292165681152.00000 to -857479500408029184.00000, saving model to Models/082--857479500408029184.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -857479500408029184.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 83/100\n",
      "302/358 [========================>.....] - ETA: 0s - loss: -867269964258607104.0000 - accuracy: 0.0000e+00\n",
      "Epoch 83: loss improved from -857479500408029184.00000 to -885638268073279488.00000, saving model to Models/083--885638268073279488.0000-0.0000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s 353us/step - loss: -885638268073279488.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 84/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -922882506477273088.0000 - accuracy: 0.0000e+00\n",
      "Epoch 84: loss improved from -885638268073279488.00000 to -914456536556765184.00000, saving model to Models/084--914456536556765184.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -914456536556765184.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 85/100\n",
      "305/358 [========================>.....] - ETA: 0s - loss: -944522132262486016.0000 - accuracy: 0.0000e+00\n",
      "Epoch 85: loss improved from -914456536556765184.00000 to -943767798566354944.00000, saving model to Models/085--943767798566354944.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -943767798566354944.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 86/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -979169049323765760.0000 - accuracy: 0.0000e+00\n",
      "Epoch 86: loss improved from -943767798566354944.00000 to -973826247446495232.00000, saving model to Models/086--973826247446495232.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -973826247446495232.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 87/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -1017490671684026368.0000 - accuracy: 0.0000e+00\n",
      "Epoch 87: loss improved from -973826247446495232.00000 to -1004434727018430464.00000, saving model to Models/087--1004434727018430464.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -1004434727018430464.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 88/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -1037681897058074624.0000 - accuracy: 0.0000e+00\n",
      "Epoch 88: loss improved from -1004434727018430464.00000 to -1035501909097578496.00000, saving model to Models/088--1035501909097578496.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 352us/step - loss: -1035501909097578496.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 89/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -1078648463358427136.0000 - accuracy: 0.0000e+00\n",
      "Epoch 89: loss improved from -1035501909097578496.00000 to -1067222407242055680.00000, saving model to Models/089--1067222407242055680.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -1067222407242055680.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 90/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -1091789482736222208.0000 - accuracy: 0.0000e+00\n",
      "Epoch 90: loss improved from -1067222407242055680.00000 to -1099539734041985024.00000, saving model to Models/090--1099539734041985024.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 350us/step - loss: -1099539734041985024.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 91/100\n",
      "294/358 [=======================>......] - ETA: 0s - loss: -1115173071402041344.0000 - accuracy: 0.0000e+00\n",
      "Epoch 91: loss improved from -1099539734041985024.00000 to -1132710419304022016.00000, saving model to Models/091--1132710419304022016.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 365us/step - loss: -1132710419304022016.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 92/100\n",
      "306/358 [========================>.....] - ETA: 0s - loss: -1187547324788768768.0000 - accuracy: 0.0000e+00\n",
      "Epoch 92: loss improved from -1132710419304022016.00000 to -1166378977175011328.00000, saving model to Models/092--1166378977175011328.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 349us/step - loss: -1166378977175011328.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 93/100\n",
      "281/358 [======================>.......] - ETA: 0s - loss: -1182404221710893056.0000 - accuracy: 0.0000e+00\n",
      "Epoch 93: loss improved from -1166378977175011328.00000 to -1200666834970345472.00000, saving model to Models/093--1200666834970345472.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 376us/step - loss: -1200666834970345472.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 94/100\n",
      "296/358 [=======================>......] - ETA: 0s - loss: -1213798302340874240.0000 - accuracy: 0.0000e+00\n",
      "Epoch 94: loss improved from -1200666834970345472.00000 to -1235718853346983936.00000, saving model to Models/094--1235718853346983936.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 358us/step - loss: -1235718853346983936.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 95/100\n",
      "301/358 [========================>.....] - ETA: 0s - loss: -1282811348681490432.0000 - accuracy: 0.0000e+00\n",
      "Epoch 95: loss improved from -1235718853346983936.00000 to -1271333821677043712.00000, saving model to Models/095--1271333821677043712.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 353us/step - loss: -1271333821677043712.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 96/100\n",
      "301/358 [========================>.....] - ETA: 0s - loss: -1309562741463187456.0000 - accuracy: 0.0000e+00\n",
      "Epoch 96: loss improved from -1271333821677043712.00000 to -1307512976911106048.00000, saving model to Models/096--1307512976911106048.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 355us/step - loss: -1307512976911106048.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 97/100\n",
      "303/358 [========================>.....] - ETA: 0s - loss: -1330697279094390784.0000 - accuracy: 0.0000e+00\n",
      "Epoch 97: loss improved from -1307512976911106048.00000 to -1344592357290409984.00000, saving model to Models/097--1344592357290409984.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 351us/step - loss: -1344592357290409984.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 98/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -1383500775262519296.0000 - accuracy: 0.0000e+00\n",
      "Epoch 98: loss improved from -1344592357290409984.00000 to -1382344089030098944.00000, saving model to Models/098--1382344089030098944.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 351us/step - loss: -1382344089030098944.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 99/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -1431479476969013248.0000 - accuracy: 0.0000e+00\n",
      "Epoch 99: loss improved from -1382344089030098944.00000 to -1420495905563344896.00000, saving model to Models/099--1420495905563344896.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 351us/step - loss: -1420495905563344896.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "Epoch 100/100\n",
      "304/358 [========================>.....] - ETA: 0s - loss: -1459967823244689408.0000 - accuracy: 0.0000e+00\n",
      "Epoch 100: loss improved from -1420495905563344896.00000 to -1459319248823255040.00000, saving model to Models/100--1459319248823255040.0000-0.0000.hdf5\n",
      "358/358 [==============================] - 0s 351us/step - loss: -1459319248823255040.0000 - accuracy: 0.0000e+00 - lr: 0.0100\n",
      "model epoch 완료\n"
     ]
    }
   ],
   "source": [
    "print('임포팅...')\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "print('임포팅 complete')\n",
    "print('---------------------------------------------------------------------------------------------------')\n",
    "print('data...')\n",
    "test = pd.read_csv('./FIFA_test.csv')\n",
    "train = pd.read_csv('./FIFA_train.csv')\n",
    "submission = pd.read_csv('./submission.csv')\n",
    "print('data complete')\n",
    "print('---------------------------------------------------------------------------------------------------')\n",
    "print('OHE...')\n",
    "train_OHE = pd.get_dummies(train, columns=[\"continent\", \"position\", \"prefer_foot\"])\n",
    "print('OHE complete(use train_OHE)')\n",
    "print('---------------------------------------------------------------------------------------------------')\n",
    "print('feature와 target 나누기')\n",
    "Label = train_OHE['value']\n",
    "InputFeature = train_OHE[[\"age\", \"reputation\", \"stat_overall\", \"stat_potential\", \n",
    "               \"stat_skill_moves\", \"continent_africa\", \"continent_asia\", \"continent_europe\",\n",
    "               \"continent_oceania\", \"continent_south america\", \"position_DF\", \"position_GK\",\n",
    "                \"position_MF\", \"position_ST\", \"prefer_foot_left\", \"prefer_foot_right\"]]\n",
    "print('---------------------------------------------------------------------------------------------------')\n",
    "print('model 만들기')\n",
    "model = Sequential()\n",
    "model.add(Dense(5, activation='linear', input_shape=(16,) ))\n",
    "model.add(Dense(10, activation='linear'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "print('완료')\n",
    "print('---------------------------------------------------------------------------------------------------')\n",
    "print('callback')\n",
    "CP = ModelCheckpoint(filepath='Models/{epoch:03d}-{loss:.4f}-{accuracy:.4f}.hdf5',\n",
    "            monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='loss',factor=0.8,patience=3, verbose=1, min_lr=1e-8)\n",
    "\n",
    "CALLBACK = [CP, LR]\n",
    "print('callback 완료')\n",
    "print('---------------------------------------------------------------------------------------------------')\n",
    "print('model epoch 돌리기')\n",
    "model.fit(x=InputFeature, y=Label, epochs=100, shuffle=True, batch_size=25, callbacks=CALLBACK)\n",
    "print('model epoch 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad3571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"Models/100--1459319248823255040.0000-0.0000.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275fd748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template\n",
    "from flask import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6adc1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb651dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "@app.route('/saerown')\n",
    "def ValuePrediction():\n",
    "    age = request.args.get(\"age\")\n",
    "    reputation = request.args.get(\"reputation\")\n",
    "    stat_overall = request.args.get(\"stat_overall\")\n",
    "    stat_potential = request.args.get(\"stat_potential\")\n",
    "    stat_skill_moves = request.args.get(\"stat_skill_moves\")\n",
    "    continent_africa = request.args.get(\"continent_africa\")\n",
    "    continent_asia = request.args.get(\"continent_asia\")\n",
    "    continent_europe = request.args.get(\"continent_europe\")\n",
    "    continent_oceania = request.args.get(\"continent_oceania\")\n",
    "    continent_south_america = request.args.get(\"continent_south america\")\n",
    "    position_DF = request.args.get(\"position_DF\")\n",
    "    position_GK = request.args.get(\"position_GK\")\n",
    "    position_MF = request.args.get(\"position_MF\")\n",
    "    position_ST = request.args.get(\"position_ST\")\n",
    "    prefer_foot_left = request.args.get(\"prefer_foot_left\")\n",
    "    prefer_foot_right = request.args.get(\"prefer_foot_right\")\n",
    "       \n",
    "    if age == None or reputation == None or stat_overall == None or stat_potential == None or stat_skill_moves == None:\n",
    "        return render_template('saerown.html', Output = '')\n",
    "    \n",
    "    Input = pd.DataFrame({\n",
    "        'age': [ float(age) ],\n",
    "        'reputation': [ float(reputation) ],\n",
    "        'stat_overall': [ float(stat_overall) ],\n",
    "        'stat_potential': [ float(stat_potential) ],\n",
    "        'stat_skill_moves': [ float(stat_skill_moves) ],\n",
    "        'continent_africa': [ float(continent_africa) ],\n",
    "        'continent_asia': [ float(continent_asia) ],\n",
    "        'continent_europe': [float(continent_europe)],\n",
    "        'continent_oceania': [float(continent_oceania)],\n",
    "        'continent_south_america': [float(continent_south_america)],\n",
    "        'position_DF': [float(position_DF)],\n",
    "        'position_GK': [float(position_GK)],\n",
    "        'position_MF': [float(position_MF)],\n",
    "        'position_ST': [float(position_ST)],\n",
    "        'prefer_foot_left': [float(prefer_foot_left)],\n",
    "        'prefer_foot_right': [float(prefer_foot_right)]\n",
    "        \n",
    "    })\n",
    "    ModelOutput = model.predict(Input)[0][0]\n",
    "\n",
    "    return render_template('saerown.html', Output = ModelOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b08ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://10.186.23.29:5000/ (Press CTRL+C to quit)\n",
      "10.186.23.29 - - [11/Jul/2022 14:11:52] \"GET / HTTP/1.1\" 200 -\n",
      "[2022-07-11 14:12:18,037] ERROR in app: Exception on /saerown [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/krc/miniforge3/envs/fastcampus/lib/python3.8/site-packages/flask/app.py\", line 2073, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/krc/miniforge3/envs/fastcampus/lib/python3.8/site-packages/flask/app.py\", line 1518, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/krc/miniforge3/envs/fastcampus/lib/python3.8/site-packages/flask/app.py\", line 1516, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/krc/miniforge3/envs/fastcampus/lib/python3.8/site-packages/flask/app.py\", line 1502, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/var/folders/c4/d406q2cs0jx8y9m35w0pn47w0000gn/T/ipykernel_5162/1400875089.py\", line 30, in ValuePrediction\n",
      "    'continent_africa': [ float(continent_africa) ],\n",
      "TypeError: float() argument must be a string or a number, not 'NoneType'\n",
      "10.186.23.29 - - [11/Jul/2022 14:12:18] \"\u001b[35m\u001b[1mGET /saerown?age=25&stat_overall=55&stat_potential=66&stat_skill_moves=3&reputation=2&continent=oceania&prefer_foot=left&position=GK HTTP/1.1\u001b[0m\" 500 -\n",
      "[2022-07-11 14:12:23,371] ERROR in app: Exception on /saerown [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/krc/miniforge3/envs/fastcampus/lib/python3.8/site-packages/flask/app.py\", line 2073, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/krc/miniforge3/envs/fastcampus/lib/python3.8/site-packages/flask/app.py\", line 1518, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/krc/miniforge3/envs/fastcampus/lib/python3.8/site-packages/flask/app.py\", line 1516, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/krc/miniforge3/envs/fastcampus/lib/python3.8/site-packages/flask/app.py\", line 1502, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/var/folders/c4/d406q2cs0jx8y9m35w0pn47w0000gn/T/ipykernel_5162/1400875089.py\", line 30, in ValuePrediction\n",
      "    'continent_africa': [ float(continent_africa) ],\n",
      "TypeError: float() argument must be a string or a number, not 'NoneType'\n",
      "10.186.23.29 - - [11/Jul/2022 14:12:23] \"\u001b[35m\u001b[1mGET /saerown?age=25&stat_overall=55&stat_potential=66&stat_skill_moves=3&reputation=2&continent=oceania&prefer_foot=left&position=GK HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52115a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
